{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbebe2bd",
   "metadata": {},
   "source": [
    "![drawing](https://scp-com.s3.amazonaws.com/314a1a15/University_of_Tennessee_at_Chattanooga_logo.svg.png)\n",
    "#### Reliable Electronics and Systems Lab\n",
    "### Adaptive Event Grouping by Impulse Signature (AEGIS)\n",
    "\n",
    "![drawing](https://cdn.dribbble.com/users/2097701/screenshots/4143230/medusa_logo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b4249",
   "metadata": {},
   "source": [
    "#### Description\n",
    "This notebook demonstrates a machine learning algorithm for classifying impulse waveforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b313cdb",
   "metadata": {},
   "source": [
    "#### Configuration\n",
    "Adjust the parameters for the experiment such as the number and complexity of the generated waveforms, and the number of feature dimensions (equal to number of polynomial coefficients) that will train the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04af941",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 1000000 # number of samples\n",
    "complexity = 3 # max poles and/or zeros for impulses\n",
    "dimensions = 18 # feature dimensions (# of coefficients in polynomial fit)\n",
    "noise = 0.001 # magnitude of generated signal noise, or None to disable\n",
    "downsample = None # downsampling factor for generated signal, or None to disable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b2786",
   "metadata": {},
   "source": [
    "#### Generate example data\n",
    "Using scipy's signal module, generate impulses with the specified complexity and number of samples. Assign each generated waveform a group based on the number of poles, zeros, and gain. Display the first three waveforms for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dfbc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "x = []\n",
    "y = []\n",
    "poles = []\n",
    "zeros = []\n",
    "gain = []\n",
    "group = []\n",
    "progress = widgets.IntProgress(value=0,max=samples,description='Progress')\n",
    "for i in range(samples):\n",
    "    poles += [randint(1,complexity)]\n",
    "    zeros += [randint(1,complexity)]\n",
    "    gain += [randint(1,complexity)]\n",
    "    x_new,y_new = signal.impulse(([1.0],[poles[i],zeros[i],gain[i]]))\n",
    "    if noise is not None:\n",
    "        x_new += np.random.normal(0,noise,len(x_new))\n",
    "    if downsample is not None:\n",
    "        x_new = signal.decimate(x_new,downsample)\n",
    "        y_new = signal.decimate(y_new,downsample)\n",
    "    x += [x_new]\n",
    "    y += [y_new]\n",
    "    group += [(poles[i] - 1) + complexity*(zeros[i] - 1) + complexity*complexity*(gain[i] - 1)]\n",
    "    progress.value = i\n",
    "plt.show(plt.plot(x[0],y[0],'.'))\n",
    "plt.show(plt.plot(x[1],y[1],'.'))\n",
    "plt.show(plt.plot(x[2],y[2],'.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7fe39c",
   "metadata": {},
   "source": [
    "#### Polynomial fit\n",
    "Using the numpy library, find the polynomial coefficients up to a degree specified by `dimension` for each waveform. Display comparisons of first three polynomial fits (orange line) to their respective waveforms (blue dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_fit = []\n",
    "y_fit = []\n",
    "coeffs = []\n",
    "for i in range(len(x)):\n",
    "    x_fit += [np.linspace(min(x[i]),max(x[i]),100)]\n",
    "    coeffs += [np.polyfit(x[i],y[i],dimensions)]\n",
    "    y_fit += [np.poly1d(coeffs[i])(x_fit[i])]\n",
    "plt.show(plt.plot(x[0],y[0],'.',x_fit[0],y_fit[0],'-'))\n",
    "plt.show(plt.plot(x[1],y[1],'.',x_fit[1],y_fit[1],'-'))\n",
    "plt.show(plt.plot(x[2],y[2],'.',x_fit[2],y_fit[2],'-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd738d3f",
   "metadata": {},
   "source": [
    "#### Feature scaling\n",
    "Now that we have determined the features of each waveform (the polynomial coefficients), they must be scaled before training the algorithm. This is done with the sklearn.preprocessing module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92996edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(coeffs)\n",
    "scaled_features = scaler.transform(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020c5dca",
   "metadata": {},
   "source": [
    "#### Split data into train and test sets\n",
    "The scaled features are split into a training set and a testing set. The ratio can be adjusted by the `test_size` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff596ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled_features,group,\n",
    "                                                    test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14cca23",
   "metadata": {},
   "source": [
    "#### Find optimal number of neighbors\n",
    "Apply sklearn's k-nearest neighbors (KNN) algorithm to the training set in multiple iterations, incrementing k. Keep track of error rates to help determine the k value that optimizes accuracy. K represents the number of neighbors (starting with the nearest) that affect which group a waveform is assigned to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e905727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "error_rate = []\n",
    "for k in range(1,20):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train,y_train)\n",
    "    pred_i = knn.predict(x_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "k_best = 1\n",
    "while error_rate[k_best - 1] >= error_rate[k_best]:\n",
    "    k_best += 1\n",
    "print('Optimal k value:',k_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de1773f",
   "metadata": {},
   "source": [
    "#### Error rate analysis\n",
    "Plot error rates as a function of k. Increasing training set size will reduce error rates for all k values. Increasing complexity will increase error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd453e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,20),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.xlabel('K')\n",
    "fig = plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73561113",
   "metadata": {},
   "source": [
    "#### Apply KNN and make predictions\n",
    "Create the KNN model and generate predicted outputs for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=k_best)\n",
    "knn.fit(x_train,y_train)\n",
    "pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d35b99b",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "Print the confusion matrix comparing test data outputs to predicted outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebef8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed788137",
   "metadata": {},
   "source": [
    "#### Classification report\n",
    "Report accuracy and other details to evaluate the effectiveness of the KNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ba4127",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred,zero_division=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777d55c0",
   "metadata": {},
   "source": [
    "#### Results\n",
    "Compare predictions to test data individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa84bfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matches = 0\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] == y_test[i]:\n",
    "        matches += 1\n",
    "pie = [matches,len(pred) - matches]\n",
    "fig = plt.pie(pie,labels=['Pass','Fail'],autopct='%1.1f%%',colors=['g','r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377579f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
